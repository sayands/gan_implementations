{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN-MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "EKyTg1asjOZC",
        "colab_type": "code",
        "outputId": "84f0dfe8-11fb-4893-e9e9-d088531aa8e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# Google Colab Setup\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WsS3jxWOxWi8",
        "outputId": "55314039-d448-440a-e4e8-4bc4b5d05ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras import initializers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "RUOoGvqHxrXq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/My Drive/app/GAN-MNIST/')\n",
        "os.environ[\"KERAS_BACKEND\"] = 'tensorflow'\n",
        "np.random.seed(10)\n",
        "\n",
        "random_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MHKmWllKyIZt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_mnist_data():\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  \n",
        "  x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "  \n",
        "  x_train = x_train.reshape(x_train.shape[0], 784)\n",
        "  \n",
        "  return (x_train, y_train, x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_Mnffv1D0B5f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_optimizer():\n",
        "  return Adam(lr=0.0002, beta_1 = 0.5)\n",
        "\n",
        "def get_generator(optimizer):\n",
        "  generator = Sequential()\n",
        "  generator.add(Dense(256, input_dim = random_dim, kernel_initializer = initializers.RandomNormal(stddev = 0.02)))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "  \n",
        "  generator.add(Dense(512))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "  \n",
        "  generator.add(Dense(1024))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "  \n",
        "  generator.add(Dense(784, activation = 'tanh'))\n",
        "  generator.compile(loss = 'binary_crossentropy', optimizer = optimizer)\n",
        "  \n",
        "  return generator\n",
        "\n",
        "def get_discriminator(optimizer):\n",
        "  discriminator = Sequential()\n",
        "  discriminator.add(Dense(1024, input_dim = 784, kernel_initializer = initializers.RandomNormal(stddev = 0.02)))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "  \n",
        "  discriminator.add(Dense(512))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "  \n",
        "  discriminator.add(Dense(256))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "  \n",
        "  discriminator.add(Dense(1, activation = 'sigmoid'))\n",
        "  discriminator.compile(loss = 'binary_crossentropy', optimizer = optimizer)\n",
        "  \n",
        "  return discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ndw5jrDT1em_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_gan_network(discriminator, random_dim, generator, optimizer):\n",
        "  discriminator.trainable = False\n",
        "  gan_input = Input(shape = (random_dim, ))\n",
        "  \n",
        "  x = generator(gan_input)\n",
        "  \n",
        "  gan_output = discriminator(x)\n",
        "  gan = Model(inputs = gan_input, outputs = gan_output)\n",
        "  gan.compile(loss = 'binary_crossentropy', optimizer = optimizer)\n",
        "  \n",
        "  return gan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "86GIuCWq2TYj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_generated_images(epoch, generator, examples = 100, dim=(10, 10), figsize = (10, 10)):\n",
        "  \n",
        "  noise = np.random.normal(0, 1, size = [examples, random_dim])\n",
        "  generated_images = generator.predict(noise)\n",
        "  generated_images = generated_images.reshape(examples, 28, 28)\n",
        "  \n",
        "  plt.figure(figsize = figsize)\n",
        "  \n",
        "  for i in range(generated_images.shape[0]):\n",
        "    plt.subplot(dim[0], dim[1], i + 1)\n",
        "    plt.imshow(generated_images[i], interpolation = 'nearest', cmap = 'gray_r')\n",
        "    plt.axis('off')\n",
        "  \n",
        "  plt.tight_layout()\n",
        "  plt.savefig('gan_generated_image_epoch_%d.png' % epoch)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dpm9TsYKbvuJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(epochs = 1, batch_size = 128):\n",
        "  x_train, y_train, x_test, y_test = load_mnist_data()\n",
        "  \n",
        "  batch_count = x_train.shape[0] / batch_size\n",
        "  \n",
        "  adam = get_optimizer()\n",
        "  generator = get_generator(adam)\n",
        "  discriminator = get_discriminator(adam)\n",
        "  gan = get_gan_network(discriminator, random_dim, generator, adam)\n",
        "  \n",
        "  for e in range(1, epochs+1):\n",
        "    str_display = '-'*15 + 'Epoch ' + str(e) + '-'*15\n",
        "    print(str_display)\n",
        "    \n",
        "    for _ in tqdm(range(int(batch_count))):\n",
        "      noise = np.random.normal(0, 1, size = [batch_size, random_dim])\n",
        "      image_batch = x_train[np.random.randint(0, x_train.shape[0], size = batch_size)]\n",
        "      \n",
        "      # Generate fake MNIST images\n",
        "      generated_images = generator.predict(noise)\n",
        "      X = np.concatenate([image_batch, generated_images])\n",
        "      \n",
        "      y_dis = np.zeros(2*batch_size)\n",
        "      y_dis[:batch_size] = 0.9\n",
        "      \n",
        "      # Train discriminator\n",
        "      discriminator.trainable = True\n",
        "      discriminator.train_on_batch(X, y_dis)\n",
        "      \n",
        "      # Train generator\n",
        "      noise = np.random.normal(0, 1, size = [batch_size, random_dim])\n",
        "      y_gen = np.ones(batch_size)\n",
        "      discriminator.trainable = False\n",
        "      gan.train_on_batch(noise, y_gen)\n",
        "      \n",
        "    if e == 1 or e%20 == 0:\n",
        "       plot_generated_images(e, generator)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9g_3e94aeJP5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(400, 128)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}